{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variables and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from curses import meta\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import openai\n",
    "from langchain.document_loaders import Docx2txtLoader\n",
    "\n",
    "OPENAI_API_KEY = st.secrets.get(\"OPENAI_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"ls__b060afcb95f84771b911bb20e5955706\"\n",
    "# os.environ [\"LANGCHAIN_PROJECT\"] = \"My Project Name\" # Optional: \"default\" is used if not set\n",
    "\n",
    "TRANSCRIPT_PATH = \"data/transcripts\"\n",
    "ANNOTATIONS_PATH = \"data/annotations\"\n",
    "ASSISTANT_ID = \"asst_XfSqQlAPl7opg5fsMCjE9lfL\"\n",
    "transcript_files = os.listdir(TRANSCRIPT_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a dataframe from transcript docs. \n",
    "It's ok to re-run this script because it's checked for duplicates later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>transcript</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sean Taylor Catapult-X Educator Interview - De...</td>\n",
       "      <td>This transcript was exported on Dec 18, 2023 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sarah Dorey Webster Catapult-X Educator Interv...</td>\n",
       "      <td>This transcript was exported on Dec 18, 2023 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Neil T. McGovern Catapult-X Educator Interview...</td>\n",
       "      <td>This transcript was exported on Dec 18, 2023 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amanda Fuller CB Amazon loyalist_Millennial.docx</td>\n",
       "      <td>This transcript was exported on Dec 18, 2023 -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patrick E Mckernan Catapult-X Educator Intervi...</td>\n",
       "      <td>This transcript was exported on Jan 11, 2024 -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                file  \\\n",
       "0  Sean Taylor Catapult-X Educator Interview - De...   \n",
       "1  Sarah Dorey Webster Catapult-X Educator Interv...   \n",
       "2  Neil T. McGovern Catapult-X Educator Interview...   \n",
       "3   Amanda Fuller CB Amazon loyalist_Millennial.docx   \n",
       "4  Patrick E Mckernan Catapult-X Educator Intervi...   \n",
       "\n",
       "                                          transcript  \n",
       "0  This transcript was exported on Dec 18, 2023 -...  \n",
       "1  This transcript was exported on Dec 18, 2023 -...  \n",
       "2  This transcript was exported on Dec 18, 2023 -...  \n",
       "3  This transcript was exported on Dec 18, 2023 -...  \n",
       "4  This transcript was exported on Jan 11, 2024 -...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcripts = []  # List to store file and transcript information\n",
    "\n",
    "for file in transcript_files:\n",
    "    if file.endswith('.docx'):  # Process only .docx files\n",
    "        doc = Docx2txtLoader(os.path.join(TRANSCRIPT_PATH, file))\n",
    "        transcript = doc.load()[0].page_content\n",
    "        transcripts.append({\"file\": file, \"transcript\": transcript})\n",
    "\n",
    "# Create DataFrame from the collected data\n",
    "transcripts_df = pd.DataFrame(transcripts, columns=[\"file\", \"transcript\"])\n",
    "transcripts_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge transcripts with survey data and create a dataframe with all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import re\n",
    "survey_data = pd.read_csv(\"data/survey_data.csv\")\n",
    "\n",
    "for index, row in transcripts_df.iterrows():\n",
    "    # Extract last name from file name\n",
    "    file_name = row['file']\n",
    "    transcript = row['transcript']\n",
    "    \n",
    "    # Separate keywords with whitespace characters, hyphens, or underscores\n",
    "    keywords = re.findall(r\"[\\w'-]+\", file_name)\n",
    "    \n",
    "    # filter keywords to first two name-sized words\n",
    "    keywords = [keyword for keyword in keywords if len(keyword) >= 3]\n",
    "    first_name = keywords[0]\n",
    "    last_name = keywords[1]\n",
    "    \n",
    "    # find survey data for this person by filtering each name\n",
    "    filtered_data = survey_data[survey_data['RecipientFirstName'].str.contains(first_name, case=False) & survey_data['RecipientLastName'].str.contains(last_name, case=False)]\n",
    "    \n",
    "    if filtered_data.empty:\n",
    "        print(f\"Could not find survey data for {first_name} {last_name}\")\n",
    "        continue\n",
    "\n",
    "    # add survey data to transcript dataframe: Age Group, Email, Role\n",
    "    transcripts_df.loc[index, 'ResponseId'] = filtered_data['ResponseId'].values[0]\n",
    "    transcripts_df.loc[index, 'FirstName'] = filtered_data['RecipientFirstName'].values[0]\n",
    "    transcripts_df.loc[index, 'LastName'] = filtered_data['RecipientLastName'].values[0]\n",
    "    transcripts_df.loc[index, 'Email'] = filtered_data['RecipientEmail'].values[0]\n",
    "    transcripts_df.loc[index, 'AgeGroup'] = filtered_data['Q15'].values[0]\n",
    "    transcripts_df.loc[index, 'InstitutionName'] = filtered_data['InstitutionName'].values[0]\n",
    "    transcripts_df.loc[index, 'District'] = filtered_data['ParentName'].values[0]\n",
    "    transcripts_df.loc[index, 'City'] = filtered_data['MailingCity'].values[0]\n",
    "    transcripts_df.loc[index, 'State'] = filtered_data['MailingState'].values[0]\n",
    "    transcripts_df.loc[index, 'Role'] = filtered_data['Q2'].values[0]\n",
    "    transcripts_df.loc[index, 'Subjects'] = filtered_data['Q3'].values[0]\n",
    "    transcripts_df.loc[index, 'Courses'] = filtered_data['Q4'].values[0]\n",
    "    transcripts_df.loc[index, 'TopOfMind'] = filtered_data['Q5'].values[0]\n",
    "    transcripts_df.loc[index, 'Carolina Familiarity'] = filtered_data['Q6_1'].values[0]\n",
    "    transcripts_df.loc[index, 'Fisher Familiarity'] = filtered_data['Q6_2'].values[0]\n",
    "    transcripts_df.loc[index, 'Flinn Scientific Familiarity'] = filtered_data['Q6_3'].values[0]\n",
    "    transcripts_df.loc[index, 'PLTW Familiarity'] = filtered_data['Q6_4'].values[0]\n",
    "    transcripts_df.loc[index, 'Sargent Welch Familiarity'] = filtered_data['Q6_5'].values[0]\n",
    "    transcripts_df.loc[index, 'Thomas Scientific Familiarity'] = filtered_data['Q6_6'].values[0]\n",
    "    transcripts_df.loc[index, 'Wards/VWR Familiarity'] = filtered_data['Q6_7'].values[0]\n",
    "    transcripts_df.loc[index, 'BioRad Familiarity'] = filtered_data['Q6_8'].values[0]\n",
    "    transcripts_df.loc[index, 'BioCorp Familiarity'] = filtered_data['Q6_9'].values[0]\n",
    "    transcripts_df.loc[index, 'Amazon Familiarity'] = filtered_data['Q6_10'].values[0]\n",
    "    transcripts_df.loc[index, 'Nasco Familiarity'] = filtered_data['Q6_11'].values[0]\n",
    "    transcripts_df.loc[index, 'Frey/School Specialty Familiarity'] = filtered_data['Q6_12'].values[0]\n",
    "    transcripts_df.loc[index, 'Primary Vendor'] = filtered_data['Q7'].values[0]\n",
    "    transcripts_df.loc[index, 'Top Vendor Qualities'] = filtered_data['Q8'].values[0]\n",
    "    transcripts_df.loc[index, 'Years in Eduacation'] = filtered_data['Q14'].values[0]\n",
    "transcripts_df\n",
    "\n",
    "# save the dataframe to a csv file\n",
    "transcripts_df.to_csv(\"data/transcripts.csv\", index=False)\n",
    "\n",
    "# save a dataframe with the transcripts dropped\n",
    "transcripts_df_trimmed = transcripts_df.drop(columns=['transcript'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process interview snapshots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_runnable,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "instructions = \"\"\"As the Interview Snapshot Compiler, my role is to assist Carolina Biological Supply Company in their market research by creating interview snapshots from primary sources. I output markdown in the following format: \n",
    "## [Interviewee Name], [Institution Name], [City, State]\n",
    "\n",
    "Category: [Carolina loyalist | Flinn loyalist | Carolina + Flinn | Other]  \n",
    "Generation: [Generation name and year range]\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Facts\n",
    "- **Position:** [Position]\n",
    "- **Teaching Areas:** [Teaching Areas]\n",
    "- **Background:** [Background]\n",
    "- **School Type:** [School Type]\n",
    "- **Purchasing Role:** [Purchasing Role]\n",
    "- **Unique Fact:** [Unique Fact]\n",
    "\n",
    "### Memorable Quote\n",
    "- \"[Memorable quote]\" [timestamp] ([brief context])\n",
    "- \"[Memorable quote]\" [timestamp] ([brief context])\n",
    "- \"[Memorable quote]\" [timestamp] ([brief context])\n",
    "\n",
    "### Buyer’s Journey\n",
    "- [Brief notes from each step of this buyer's journey such as: Identification of Needs, Research and Consideration, Decision-Making, Vendor Selection, Post-Purchase Evaluation]\n",
    "\n",
    "### Insights\n",
    "- [Insight from interview]\n",
    "\n",
    "### Opportunities\n",
    "- [Opportunity/need identified]\n",
    "\n",
    "\n",
    "### Video, Transcript & Survey Responses\n",
    "- [to be added later]\n",
    "\"\"\"\n",
    "\n",
    "# Chat Prompt Template from instructions\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\", instructions),\n",
    "      (\"human\", \"Process transcript for email: {email} transcript:\\n {text}\"),\n",
    "    ]\n",
    "  )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0)\n",
    "\n",
    "chain = prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process annotations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a chain for getting annotations from transcript text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.openai_functions import (\n",
    "    create_structured_output_runnable,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "from typing import List\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class Annotation(BaseModel):\n",
    "  email: str = Field(..., description=\"The email of the interviewee.\")\n",
    "  text_segment: str = Field(..., description=\"A statement by the customer that relates to one of the study themes. Does not apply to statments by Kimbery or Daylene.\")\n",
    "  summary: str = Field(..., description=\"A one-line summary of the annotated segment.\")\n",
    "  context: str = Field(..., description=\"The full context of the text segment, including the interviewer question.\")\n",
    "  themes: List[str] = Field(..., description=\"The themes that apply to the text segment.\")\n",
    "  brand: str = Field(..., description=\"Brand that applies to the text segment.\")\n",
    "  products_purchased: List[str] = Field(..., description=\"Products purchased by the interviewee.\")\n",
    "  time_stamp: str = Field(..., description=\"The time stamp of the text segment.\")\n",
    "\n",
    "class AnnotationsList(BaseModel):\n",
    "    annotations: List[Annotation]\n",
    "\n",
    "\n",
    "instructions = \"\"\"As Transcript Pro, analyze educator interview transcripts for market research. Key areas include:\n",
    "\n",
    "  1. **Brand Perception:** Views on brands like Carolina, Flinn Scientific, Amazon, VWR, Ward's, etc.\n",
    "  2. **Product Quality:** Discussions about product durability, effectiveness, quality.\n",
    "  3. **Customer Service:** Experiences with customer service.\n",
    "  4. **Purchasing Experience:** Ease or difficulty in purchasing.\n",
    "  5. **Digital Resources:** Use of digital/virtual teaching tools.\n",
    "  6. **Environmental Sustainability:** Eco-friendly practices in education.\n",
    "  7. **Educational Policies:** Policy influence on purchases.\n",
    "  8. **Customer Experience:** Brand experiences, positive or negative.\n",
    "  9. **Buying Habits:** Timing and methods of buying.\n",
    "  10. **Purchasing Patterns:** What is bought from various vendors.\n",
    "  11. **Vendor Comparison:** Comparisons between Carolina Biological and others.\n",
    "  12. **Budget and Timing:** Budget and purchase timing considerations.\n",
    "  13. **Generational Insights:** Generational differences in buying.\n",
    "  14. **Carolina Purchases:** Specific products purchased from Carolina Biological Supply.\n",
    "  15. **Flinn Purchases:** Specific products purchased from Flinn Scientific.\n",
    "\n",
    "  Focus on processing and summarizing interviewee statements accurately and objectively, maintaining consistency in coding.\n",
    "  \"\"\"\n",
    "\n",
    "  # Chat Prompt Template from instructions\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "      (\"system\", instructions),\n",
    "      (\"human\", \"Process transcript for email: {email} transcript:\\n {text}\"),\n",
    "    ]\n",
    "  )\n",
    "\n",
    "runnable = create_structured_output_runnable(AnnotationsList, ChatOpenAI(model=\"gpt-4-1106-preview\", temperature=0), prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a list of transcripts to process, skipping any with csv files already created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pmckernan@troyusd.org',\n",
       " 'ekaretny@bhprsd.org',\n",
       " 'bbesspashak@philasd.org',\n",
       " 'robin.hurst@lyon.kyschools.us',\n",
       " 'joemyers@npsne.org',\n",
       " 'gbuchsen@pasdedu.org',\n",
       " 'robert.lehman@pgcps.org',\n",
       " 'nevans@philasd.org',\n",
       " 'tclark@claytonps.org']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create a list of rows to process\n",
    "rows_to_process = list(transcripts_df.iterrows())\n",
    "\n",
    "# filter out rows that have already been processed\n",
    "for index, row in transcripts_df.iterrows():\n",
    "    participant_email = row['Email']\n",
    "    csv_file_path = f\"{ANNOTATIONS_PATH}/{participant_email}.csv\"\n",
    "    if os.path.exists(csv_file_path):\n",
    "        rows_to_process = [r for r in rows_to_process if r[0] != index]\n",
    "        \n",
    "        \n",
    "# display the emails of the rows to process\n",
    "emails_to_process = [r[1]['Email'] for r in rows_to_process]\n",
    "emails_to_process\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the interview snapshots and output md files for each snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_snapshot(row):\n",
    "    transcript = row[1]['transcript']\n",
    "    participant_email = row[1]['Email']\n",
    "    print(f\"Processing transcript for {participant_email}\")\n",
    "    # Run the chain\n",
    "    result = chain.invoke({\"email\": participant_email, \"text\": transcript})\n",
    "    # Save the results to an md file\n",
    "    markdown = result.content\n",
    "    md_file_path = f\"{ANNOTATIONS_PATH}/{participant_email}.md\"\n",
    "    with open(md_file_path, \"w\") as f:\n",
    "        f.write(markdown)\n",
    "    return markdown\n",
    "\n",
    "snapshots_to_process = rows_to_process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this to process snapshots one at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing transcript for joemyers@npsne.org\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'## Joe Myers, Norfolk Senior High School, Norfolk, NE\\n\\nCategory: Flinn loyalist  \\nGeneration: Generation X (1965-1980)\\n\\n---\\n\\n### Quick Facts\\n- **Position:** Science Teacher\\n- **Teaching Areas:** Biology, AP Environmental Science\\n- **Background:** Certified Spanish interpreter, over 20 years of teaching experience\\n- **School Type:** Public High School\\n- **Purchasing Role:** Influencer/Recommender\\n- **Unique Fact:** Founder of the robotics club, varsity men\\'s soccer coach, past president of Nebraska Science Teachers Association, grant writer\\n\\n### Memorable Quote\\n- \"I think we need to find ways to make it more authentic, which isn\\'t easy and it\\'s not cheap, but we\\'re finding that if our kids are building models, even if they\\'re just building a simple DNA model out of beads and pipe cleaners, they just don\\'t have the tactile skills to build things.\" [30:43] (Discussing the importance of hands-on learning)\\n- \"I know that the trend, especially since covid has been to create loads of digital interactive things, but it\\'s sort of like in the adult world, people are really craving and really paying premium for hands-on and real life experiences.\" [31:38] (On the trend towards digital learning)\\n- \"It\\'s really hard for teachers to compete with TikTok and games and social media and just kids wanting to interact with their friends that aren\\'t in the classroom.\" [32:58] (On the challenge of engaging students in the presence of technology)\\n\\n### Buyer’s Journey\\n- **Identification of Needs:** Curriculum adoption every five years, need for hands-on materials and technology like Vernier.\\n- **Research and Consideration:** Considers various vendors, including Carolina, NASCO, and School Specialty (formerly Fry).\\n- **Decision-Making:** Decisions are made at the department level, with some larger purchases requiring school board approval.\\n- **Vendor Selection:** Prefers vendors that are reliable in fulfilling orders, such as Carolina and Flinn.\\n- **Post-Purchase Evaluation:** Seems satisfied with current vendors, no disasters reported with orders.\\n\\n### Insights\\n- Joe Myers values hands-on learning experiences and is concerned about the trend towards digital learning overshadowing the tactile, real-world skills students need.\\n- There is a challenge in engaging students due to the distractions of smartphones and social media in the classroom.\\n- The school has moved away from dissections in biology, now only occurring in anatomy and physiology courses, partly due to changes in state testing focus.\\n\\n### Opportunities\\n- There is an opportunity for vendors to integrate technology in a way that competes with or utilizes students\\' smartphones for educational purposes.\\n- There is a need for entry-level biology courses to accommodate the wide range of student abilities and preparedness.\\n\\n### Video, Transcript & Survey Responses\\n- [to be added later]'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# process first snapshot and remove it from the list\n",
    "snapshot = process_snapshot(snapshots_to_process[0])\n",
    "snapshots_to_process = snapshots_to_process[1:]\n",
    "snapshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run to process the remaining snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing transcript for gbuchsen@pasdedu.org\n",
      "Processing transcript for robert.lehman@pgcps.org\n",
      "Processing transcript for nevans@philasd.org\n",
      "Processing transcript for tclark@claytonps.org\n"
     ]
    }
   ],
   "source": [
    "# process the rest of the snapshots\n",
    "for snapshot in snapshots_to_process:\n",
    "    process_snapshot(snapshot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stitch the md files together into a single md file\n",
    "md_files = os.listdir(ANNOTATIONS_PATH)\n",
    "md_files = [f for f in md_files if f.endswith('.md')]\n",
    "md_files.sort()\n",
    "\n",
    "with open(\"data/snapshots.md\", \"w\") as outfile:\n",
    "    for fname in md_files:\n",
    "        with open(os.path.join(ANNOTATIONS_PATH, fname)) as infile:\n",
    "            outfile.write(infile.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done processing transcripts\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def process_transcript(row):\n",
    "    # get the transcript text and email\n",
    "    text = row['transcript']\n",
    "    participant_email = row['Email']\n",
    "    \n",
    "    # check if the CSV file already exists\n",
    "    csv_file_path = f\"{ANNOTATIONS_PATH}/{participant_email}.csv\"\n",
    "    if os.path.exists(csv_file_path):\n",
    "        print(f\"CSV file for {participant_email} already exists. Skipping...\")\n",
    "        return\n",
    "    else:\n",
    "        print(f\"Processing transcript for {participant_email}\")\n",
    "    # run the transcript through the model\n",
    "    try:\n",
    "        response = runnable.invoke({\"email\": participant_email, \"text\": text})\n",
    "        annotations_df = pd.DataFrame.from_records([annotation.dict() for annotation in response.annotations])\n",
    "        # merge annotations with transcript data\n",
    "        annotations_df.to_csv(csv_file_path, index=False)\n",
    "        # save annotations to a csv file\n",
    "        print(f\"Saved annotations for {participant_email}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing transcript for {participant_email}. Skipping...\")\n",
    "\n",
    "# Create a list of rows to process\n",
    "rows_to_process = transcripts_df.iterrows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process interview snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run manually to process the next transcript until all are processed\n",
    "def process_next_transcript():\n",
    "    # get the next transcript\n",
    "    row = next(rows_to_process)\n",
    "    process_transcript(row)\n",
    "    \n",
    "process_next_transcript()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine the annotations and save as annotations.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>text_segment</th>\n",
       "      <th>context</th>\n",
       "      <th>theme</th>\n",
       "      <th>brand</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>file</th>\n",
       "      <th>ResponseId</th>\n",
       "      <th>FirstName</th>\n",
       "      <th>LastName</th>\n",
       "      <th>...</th>\n",
       "      <th>Wards/VWR Familiarity</th>\n",
       "      <th>BioRad Familiarity</th>\n",
       "      <th>BioCorp Familiarity</th>\n",
       "      <th>Amazon Familiarity</th>\n",
       "      <th>Nasco Familiarity</th>\n",
       "      <th>Frey/School Specialty Familiarity</th>\n",
       "      <th>Primary Vendor</th>\n",
       "      <th>Top Vendor Qualities</th>\n",
       "      <th>Years in Eduacation</th>\n",
       "      <th>themes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>teresa_a_massey@dekalbschoolsga.org</td>\n",
       "      <td>I buy, I'm the one that even though I may not ...</td>\n",
       "      <td>Teresa Massey (02:38):\\n\\nOkay, so I buy, I'm ...</td>\n",
       "      <td>['Purchasing Experience', 'Buying Habits']</td>\n",
       "      <td>[]</td>\n",
       "      <td>02:38</td>\n",
       "      <td>Teresa Massey Catapult-X Educator Interview - ...</td>\n",
       "      <td>R_3nknLxkysbILp8B</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>Massey</td>\n",
       "      <td>...</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Carolina Biological,Fisher/Thermo Fisher Scien...</td>\n",
       "      <td>District approved vendor,Reliable</td>\n",
       "      <td>Over 20 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>teresa_a_massey@dekalbschoolsga.org</td>\n",
       "      <td>I really prefer something that they can manipu...</td>\n",
       "      <td>Teresa Massey (03:31):\\n\\nI really prefer some...</td>\n",
       "      <td>['Product Quality', 'Digital Resources']</td>\n",
       "      <td>[]</td>\n",
       "      <td>03:31</td>\n",
       "      <td>Teresa Massey Catapult-X Educator Interview - ...</td>\n",
       "      <td>R_3nknLxkysbILp8B</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>Massey</td>\n",
       "      <td>...</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Carolina Biological,Fisher/Thermo Fisher Scien...</td>\n",
       "      <td>District approved vendor,Reliable</td>\n",
       "      <td>Over 20 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>teresa_a_massey@dekalbschoolsga.org</td>\n",
       "      <td>Well, our timing is never the same from year t...</td>\n",
       "      <td>Teresa Massey (04:30):\\n\\nWell, our timing is ...</td>\n",
       "      <td>['Budget and Timing']</td>\n",
       "      <td>[]</td>\n",
       "      <td>04:30</td>\n",
       "      <td>Teresa Massey Catapult-X Educator Interview - ...</td>\n",
       "      <td>R_3nknLxkysbILp8B</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>Massey</td>\n",
       "      <td>...</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Carolina Biological,Fisher/Thermo Fisher Scien...</td>\n",
       "      <td>District approved vendor,Reliable</td>\n",
       "      <td>Over 20 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>teresa_a_massey@dekalbschoolsga.org</td>\n",
       "      <td>This past year we decided on what we were goin...</td>\n",
       "      <td>Teresa Massey (05:21):\\n\\nIn a way, we kind of...</td>\n",
       "      <td>['Purchasing Patterns', 'Digital Resources']</td>\n",
       "      <td>[]</td>\n",
       "      <td>05:21</td>\n",
       "      <td>Teresa Massey Catapult-X Educator Interview - ...</td>\n",
       "      <td>R_3nknLxkysbILp8B</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>Massey</td>\n",
       "      <td>...</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Carolina Biological,Fisher/Thermo Fisher Scien...</td>\n",
       "      <td>District approved vendor,Reliable</td>\n",
       "      <td>Over 20 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>teresa_a_massey@dekalbschoolsga.org</td>\n",
       "      <td>We use it for a while. It's not new to the sch...</td>\n",
       "      <td>Teresa Massey (06:51):\\n\\nWe use it for a whil...</td>\n",
       "      <td>['Digital Resources']</td>\n",
       "      <td>['STEMscopes']</td>\n",
       "      <td>06:51</td>\n",
       "      <td>Teresa Massey Catapult-X Educator Interview - ...</td>\n",
       "      <td>R_3nknLxkysbILp8B</td>\n",
       "      <td>Teresa</td>\n",
       "      <td>Massey</td>\n",
       "      <td>...</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Carolina Biological,Fisher/Thermo Fisher Scien...</td>\n",
       "      <td>District approved vendor,Reliable</td>\n",
       "      <td>Over 20 years</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ruberg@eths202.org</td>\n",
       "      <td>Honestly, the best experiences I've had are ou...</td>\n",
       "      <td>Kimberly Herder (27:55): So on those catalogs,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Carolina</td>\n",
       "      <td>27:55</td>\n",
       "      <td>Greg Ruber Strohm Catapult-X Educator Intervie...</td>\n",
       "      <td>R_11bIskMPuh55EKW</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Ruber</td>\n",
       "      <td>...</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Carolina Biological,Amazon</td>\n",
       "      <td>District approved vendor,Free shipping (unlimi...</td>\n",
       "      <td>4-9 years</td>\n",
       "      <td>['Customer Experience', 'Vendor Comparison']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ruberg@eths202.org</td>\n",
       "      <td>I purchase lab supplies. Sometimes it's from l...</td>\n",
       "      <td>Kimberly Herder (14:39): Where do you get the ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>14:39</td>\n",
       "      <td>Greg Ruber Strohm Catapult-X Educator Intervie...</td>\n",
       "      <td>R_11bIskMPuh55EKW</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Ruber</td>\n",
       "      <td>...</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Carolina Biological,Amazon</td>\n",
       "      <td>District approved vendor,Free shipping (unlimi...</td>\n",
       "      <td>4-9 years</td>\n",
       "      <td>['Purchasing Patterns', 'Vendor Comparison']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ruberg@eths202.org</td>\n",
       "      <td>I think I do. I'm very fortunate that I'm at a...</td>\n",
       "      <td>Kimberly Herder (16:26): Do you have a budget?...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>16:26</td>\n",
       "      <td>Greg Ruber Strohm Catapult-X Educator Intervie...</td>\n",
       "      <td>R_11bIskMPuh55EKW</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Ruber</td>\n",
       "      <td>...</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Carolina Biological,Amazon</td>\n",
       "      <td>District approved vendor,Free shipping (unlimi...</td>\n",
       "      <td>4-9 years</td>\n",
       "      <td>['Budget and Timing']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ruberg@eths202.org</td>\n",
       "      <td>I start that process by asking the students. S...</td>\n",
       "      <td>Kimberly Herder (06:57): Okay, so you're doing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>06:57</td>\n",
       "      <td>Greg Ruber Strohm Catapult-X Educator Intervie...</td>\n",
       "      <td>R_11bIskMPuh55EKW</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Ruber</td>\n",
       "      <td>...</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Carolina Biological,Amazon</td>\n",
       "      <td>District approved vendor,Free shipping (unlimi...</td>\n",
       "      <td>4-9 years</td>\n",
       "      <td>['Educational Policies']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ruberg@eths202.org</td>\n",
       "      <td>I feel like I have put my hands in everything ...</td>\n",
       "      <td>Kimberly Herder (11:37): So what are some of t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>General</td>\n",
       "      <td>11:37</td>\n",
       "      <td>Greg Ruber Strohm Catapult-X Educator Intervie...</td>\n",
       "      <td>R_11bIskMPuh55EKW</td>\n",
       "      <td>Gregory</td>\n",
       "      <td>Ruber</td>\n",
       "      <td>...</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Aware of (don't use)</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Current Vendor</td>\n",
       "      <td>Never heard of</td>\n",
       "      <td>Carolina Biological,Amazon</td>\n",
       "      <td>District approved vendor,Free shipping (unlimi...</td>\n",
       "      <td>4-9 years</td>\n",
       "      <td>['Digital Resources']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  email  \\\n",
       "0   teresa_a_massey@dekalbschoolsga.org   \n",
       "1   teresa_a_massey@dekalbschoolsga.org   \n",
       "2   teresa_a_massey@dekalbschoolsga.org   \n",
       "3   teresa_a_massey@dekalbschoolsga.org   \n",
       "4   teresa_a_massey@dekalbschoolsga.org   \n",
       "..                                  ...   \n",
       "0                    ruberg@eths202.org   \n",
       "1                    ruberg@eths202.org   \n",
       "2                    ruberg@eths202.org   \n",
       "3                    ruberg@eths202.org   \n",
       "4                    ruberg@eths202.org   \n",
       "\n",
       "                                         text_segment  \\\n",
       "0   I buy, I'm the one that even though I may not ...   \n",
       "1   I really prefer something that they can manipu...   \n",
       "2   Well, our timing is never the same from year t...   \n",
       "3   This past year we decided on what we were goin...   \n",
       "4   We use it for a while. It's not new to the sch...   \n",
       "..                                                ...   \n",
       "0   Honestly, the best experiences I've had are ou...   \n",
       "1   I purchase lab supplies. Sometimes it's from l...   \n",
       "2   I think I do. I'm very fortunate that I'm at a...   \n",
       "3   I start that process by asking the students. S...   \n",
       "4   I feel like I have put my hands in everything ...   \n",
       "\n",
       "                                              context  \\\n",
       "0   Teresa Massey (02:38):\\n\\nOkay, so I buy, I'm ...   \n",
       "1   Teresa Massey (03:31):\\n\\nI really prefer some...   \n",
       "2   Teresa Massey (04:30):\\n\\nWell, our timing is ...   \n",
       "3   Teresa Massey (05:21):\\n\\nIn a way, we kind of...   \n",
       "4   Teresa Massey (06:51):\\n\\nWe use it for a whil...   \n",
       "..                                                ...   \n",
       "0   Kimberly Herder (27:55): So on those catalogs,...   \n",
       "1   Kimberly Herder (14:39): Where do you get the ...   \n",
       "2   Kimberly Herder (16:26): Do you have a budget?...   \n",
       "3   Kimberly Herder (06:57): Okay, so you're doing...   \n",
       "4   Kimberly Herder (11:37): So what are some of t...   \n",
       "\n",
       "                                           theme           brand time_stamp  \\\n",
       "0     ['Purchasing Experience', 'Buying Habits']              []      02:38   \n",
       "1       ['Product Quality', 'Digital Resources']              []      03:31   \n",
       "2                          ['Budget and Timing']              []      04:30   \n",
       "3   ['Purchasing Patterns', 'Digital Resources']              []      05:21   \n",
       "4                          ['Digital Resources']  ['STEMscopes']      06:51   \n",
       "..                                           ...             ...        ...   \n",
       "0                                            NaN        Carolina      27:55   \n",
       "1                                            NaN         General      14:39   \n",
       "2                                            NaN         General      16:26   \n",
       "3                                            NaN         General      06:57   \n",
       "4                                            NaN         General      11:37   \n",
       "\n",
       "                                                 file         ResponseId  \\\n",
       "0   Teresa Massey Catapult-X Educator Interview - ...  R_3nknLxkysbILp8B   \n",
       "1   Teresa Massey Catapult-X Educator Interview - ...  R_3nknLxkysbILp8B   \n",
       "2   Teresa Massey Catapult-X Educator Interview - ...  R_3nknLxkysbILp8B   \n",
       "3   Teresa Massey Catapult-X Educator Interview - ...  R_3nknLxkysbILp8B   \n",
       "4   Teresa Massey Catapult-X Educator Interview - ...  R_3nknLxkysbILp8B   \n",
       "..                                                ...                ...   \n",
       "0   Greg Ruber Strohm Catapult-X Educator Intervie...  R_11bIskMPuh55EKW   \n",
       "1   Greg Ruber Strohm Catapult-X Educator Intervie...  R_11bIskMPuh55EKW   \n",
       "2   Greg Ruber Strohm Catapult-X Educator Intervie...  R_11bIskMPuh55EKW   \n",
       "3   Greg Ruber Strohm Catapult-X Educator Intervie...  R_11bIskMPuh55EKW   \n",
       "4   Greg Ruber Strohm Catapult-X Educator Intervie...  R_11bIskMPuh55EKW   \n",
       "\n",
       "   FirstName LastName  ... Wards/VWR Familiarity    BioRad Familiarity  \\\n",
       "0     Teresa   Massey  ...        Current Vendor        Current Vendor   \n",
       "1     Teresa   Massey  ...        Current Vendor        Current Vendor   \n",
       "2     Teresa   Massey  ...        Current Vendor        Current Vendor   \n",
       "3     Teresa   Massey  ...        Current Vendor        Current Vendor   \n",
       "4     Teresa   Massey  ...        Current Vendor        Current Vendor   \n",
       "..       ...      ...  ...                   ...                   ...   \n",
       "0    Gregory    Ruber  ...  Aware of (don't use)  Aware of (don't use)   \n",
       "1    Gregory    Ruber  ...  Aware of (don't use)  Aware of (don't use)   \n",
       "2    Gregory    Ruber  ...  Aware of (don't use)  Aware of (don't use)   \n",
       "3    Gregory    Ruber  ...  Aware of (don't use)  Aware of (don't use)   \n",
       "4    Gregory    Ruber  ...  Aware of (don't use)  Aware of (don't use)   \n",
       "\n",
       "     BioCorp Familiarity    Amazon Familiarity Nasco Familiarity  \\\n",
       "0   Aware of (don't use)  Aware of (don't use)    Current Vendor   \n",
       "1   Aware of (don't use)  Aware of (don't use)    Current Vendor   \n",
       "2   Aware of (don't use)  Aware of (don't use)    Current Vendor   \n",
       "3   Aware of (don't use)  Aware of (don't use)    Current Vendor   \n",
       "4   Aware of (don't use)  Aware of (don't use)    Current Vendor   \n",
       "..                   ...                   ...               ...   \n",
       "0         Never heard of        Current Vendor    Current Vendor   \n",
       "1         Never heard of        Current Vendor    Current Vendor   \n",
       "2         Never heard of        Current Vendor    Current Vendor   \n",
       "3         Never heard of        Current Vendor    Current Vendor   \n",
       "4         Never heard of        Current Vendor    Current Vendor   \n",
       "\n",
       "   Frey/School Specialty Familiarity  \\\n",
       "0                     Current Vendor   \n",
       "1                     Current Vendor   \n",
       "2                     Current Vendor   \n",
       "3                     Current Vendor   \n",
       "4                     Current Vendor   \n",
       "..                               ...   \n",
       "0                     Never heard of   \n",
       "1                     Never heard of   \n",
       "2                     Never heard of   \n",
       "3                     Never heard of   \n",
       "4                     Never heard of   \n",
       "\n",
       "                                       Primary Vendor  \\\n",
       "0   Carolina Biological,Fisher/Thermo Fisher Scien...   \n",
       "1   Carolina Biological,Fisher/Thermo Fisher Scien...   \n",
       "2   Carolina Biological,Fisher/Thermo Fisher Scien...   \n",
       "3   Carolina Biological,Fisher/Thermo Fisher Scien...   \n",
       "4   Carolina Biological,Fisher/Thermo Fisher Scien...   \n",
       "..                                                ...   \n",
       "0                          Carolina Biological,Amazon   \n",
       "1                          Carolina Biological,Amazon   \n",
       "2                          Carolina Biological,Amazon   \n",
       "3                          Carolina Biological,Amazon   \n",
       "4                          Carolina Biological,Amazon   \n",
       "\n",
       "                                 Top Vendor Qualities Years in Eduacation  \\\n",
       "0                   District approved vendor,Reliable       Over 20 years   \n",
       "1                   District approved vendor,Reliable       Over 20 years   \n",
       "2                   District approved vendor,Reliable       Over 20 years   \n",
       "3                   District approved vendor,Reliable       Over 20 years   \n",
       "4                   District approved vendor,Reliable       Over 20 years   \n",
       "..                                                ...                 ...   \n",
       "0   District approved vendor,Free shipping (unlimi...           4-9 years   \n",
       "1   District approved vendor,Free shipping (unlimi...           4-9 years   \n",
       "2   District approved vendor,Free shipping (unlimi...           4-9 years   \n",
       "3   District approved vendor,Free shipping (unlimi...           4-9 years   \n",
       "4   District approved vendor,Free shipping (unlimi...           4-9 years   \n",
       "\n",
       "                                          themes  \n",
       "0                                            NaN  \n",
       "1                                            NaN  \n",
       "2                                            NaN  \n",
       "3                                            NaN  \n",
       "4                                            NaN  \n",
       "..                                           ...  \n",
       "0   ['Customer Experience', 'Vendor Comparison']  \n",
       "1   ['Purchasing Patterns', 'Vendor Comparison']  \n",
       "2                          ['Budget and Timing']  \n",
       "3                       ['Educational Policies']  \n",
       "4                          ['Digital Resources']  \n",
       "\n",
       "[164 rows x 36 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# combine the csv files into one\n",
    "from operator import le\n",
    "\n",
    "\n",
    "csv_files = os.listdir(\"data/annotations/\")\n",
    "annotations = []\n",
    "for file in csv_files:\n",
    "    if file.endswith('.csv'):  # Process only .csv files\n",
    "        annotation = pd.read_csv(os.path.join(\"data/annotations/\", file))\n",
    "        # merge with survey data\n",
    "        annotation_merged = pd.merge(annotation, transcripts_df_trimmed, left_on='email', right_on='Email')\n",
    "        annotations.append(annotation_merged)\n",
    "annotations\n",
    "        \n",
    "annotations_df = pd.concat(annotations)\n",
    "annotations_df.to_csv(\"data/annotations.csv\", index=False)\n",
    "annotations_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "market-analysis-OkwLYUTU-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
